{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kkrishnaa30/LGM-Tasks/blob/main/LGM_Task_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f150fe",
      "metadata": {
        "id": "a7f150fe"
      },
      "source": [
        "# LetsGrowMore (LGMVIP) - \"DATA SCIENCE INTERNSHIP\"\n",
        "\n",
        "## LGMVIP Oct-22\n",
        "\n",
        "### _Author - Krishna Khandelwal_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf79617",
      "metadata": {
        "id": "2bf79617"
      },
      "source": [
        "### Task - 4 Next Word Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "201256e9",
      "metadata": {
        "id": "201256e9"
      },
      "source": [
        "Dataset Link: https://drive.google.com/file/d/1GeUzNVqiixXHnTl8oNiQ2W3CynX_lsu2/view"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d8f672",
      "metadata": {
        "id": "b2d8f672"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d2b919fe",
      "metadata": {
        "id": "d2b919fe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a225dc58",
      "metadata": {
        "id": "a225dc58"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1621a83",
      "metadata": {
        "id": "d1621a83"
      },
      "source": [
        "We will be loading the dataset in the 'txt' variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c2aa4deb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2aa4deb",
        "outputId": "77906dfc-4962-4654-f740-d7eb26bf160e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length 581888\n"
          ]
        }
      ],
      "source": [
        "path = '1661-0.txt'\n",
        "txt = open(path, encoding='utf-8').read().lower()\n",
        "print('corpus length', len(txt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4372953",
      "metadata": {
        "id": "a4372953"
      },
      "source": [
        "Now the next process will be performing the feature engineering in our data. For this purpose, we will require a dictionary with each word in the data within the list of unique words as the key, and itâ€™s significant portions as value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "90936435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90936435",
        "outputId": "bd32fd7b-ce32-4ab4-db77-0e79853417cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique chars:  73\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(txt)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "print (\"unique chars: \",len(chars))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5135970",
      "metadata": {
        "id": "f5135970"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e6e9702",
      "metadata": {
        "id": "1e6e9702"
      },
      "source": [
        "Here we will define a sequence length which will represent the number of previous words in the sequence that will determine our next word. We will also space the sequences by 3 characters. And we will additionally store the next character (the one we need to predict) for every sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "38d6c1c5",
      "metadata": {
        "id": "38d6c1c5",
        "outputId": "a335131f-ce06-41eb-9af3-c4f0a095df96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num training examples:  193950\n"
          ]
        }
      ],
      "source": [
        "SEQUENCE_LENGTH = 39\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(txt) - SEQUENCE_LENGTH, step):\n",
        "    sentences.append(txt[i:i+SEQUENCE_LENGTH])\n",
        "    next_chars.append(txt[i+SEQUENCE_LENGTH])\n",
        "print ('num training examples: ',len(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c178411",
      "metadata": {
        "id": "7c178411"
      },
      "source": [
        "Now we will create two numpy arrays x for storing the features and y for storing its corresponding label. We will also iterate x and y if the word is available so that the corresponding position becomes 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "962e4bf8",
      "metadata": {
        "id": "962e4bf8"
      },
      "outputs": [],
      "source": [
        "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffaa3662",
      "metadata": {
        "id": "ffaa3662"
      },
      "source": [
        "Now before moving forward, have a look at a single sequence of words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f858646f",
      "metadata": {
        "id": "f858646f",
        "outputId": "02385741-f47a-4634-d325-c341e095fd24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            "  True]\n"
          ]
        }
      ],
      "source": [
        "print(X[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6987c31",
      "metadata": {
        "id": "e6987c31"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4abf4c48",
      "metadata": {
        "id": "4abf4c48"
      },
      "source": [
        "As we stated earlier, we will use the ___Recurrent Neural networks___ for next word prediction model. Here we will use the __LSTM model__, which is a very powerful RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ae6c2879",
      "metadata": {
        "id": "ae6c2879"
      },
      "outputs": [],
      "source": [
        "model = Sequential();\n",
        "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c55e2cfa",
      "metadata": {
        "id": "c55e2cfa",
        "outputId": "dd459adb-cd6a-401f-892b-22d17e16f8f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               103424    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 73)                9417      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 73)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 112,841\n",
            "Trainable params: 112,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cca7881",
      "metadata": {
        "id": "7cca7881"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f819aa91",
      "metadata": {
        "id": "f819aa91"
      },
      "source": [
        "Here we will be training the next word prediction model with 20 epochs. The model training uses RMSprop as the optimizer with a learning rate of 0.01 and uses categorical cross-entropy for loss function. With a batch size of 128 and a split of 0.5, we train our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf65c20f",
      "metadata": {
        "id": "bf65c20f",
        "outputId": "60c55fc5-e1bc-4329-a038-ade892daa481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1440/1440 [==============================] - 200s 137ms/step - loss: 1.2968 - accuracy: 0.6025 - val_loss: 2.1110 - val_accuracy: 0.4731\n",
            "Epoch 2/20\n",
            "1440/1440 [==============================] - 185s 129ms/step - loss: 1.2899 - accuracy: 0.6029 - val_loss: 2.1447 - val_accuracy: 0.4667\n",
            "Epoch 3/20\n",
            "1440/1440 [==============================] - 187s 130ms/step - loss: 1.2853 - accuracy: 0.6045 - val_loss: 2.1801 - val_accuracy: 0.4670\n",
            "Epoch 4/20\n",
            "1440/1440 [==============================] - 185s 128ms/step - loss: 1.2786 - accuracy: 0.6068 - val_loss: 2.1743 - val_accuracy: 0.4693\n",
            "Epoch 5/20\n",
            "1440/1440 [==============================] - 186s 129ms/step - loss: 1.2745 - accuracy: 0.6080 - val_loss: 2.1988 - val_accuracy: 0.4578\n",
            "Epoch 6/20\n",
            "1440/1440 [==============================] - 184s 128ms/step - loss: 1.2721 - accuracy: 0.6082 - val_loss: 2.1932 - val_accuracy: 0.4658\n",
            "Epoch 7/20\n",
            "1440/1440 [==============================] - 185s 128ms/step - loss: 1.2679 - accuracy: 0.6098 - val_loss: 2.2035 - val_accuracy: 0.4688\n",
            "Epoch 8/20\n",
            " 234/1440 [===>..........................] - ETA: 2:32 - loss: 1.2347 - accuracy: 0.6168"
          ]
        }
      ],
      "source": [
        "optimizer = RMSprop(lr= 0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1780e8e5",
      "metadata": {
        "id": "1780e8e5"
      },
      "source": [
        "We have successfully trained our model and the final accuracy in the training stage that we got is __60.74%__ which is pretty acceptable considering we haven't even fully configured neither our model nor the dataset to their full potential."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c8f0a88",
      "metadata": {
        "id": "6c8f0a88"
      },
      "source": [
        "## Saving the Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c230a88e",
      "metadata": {
        "id": "c230a88e"
      },
      "source": [
        "Now we have successfully trained our model, before moving forward to evaluating our model, it will be better to save this model for our future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40574c88",
      "metadata": {
        "id": "40574c88"
      },
      "outputs": [],
      "source": [
        "model.save('LGMVIP_Task4_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "model = load_model('LGMVIP_Task4_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8490d2e",
      "metadata": {
        "id": "b8490d2e"
      },
      "source": [
        "## Evaluating the Next Word Prediction Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "839a4379",
      "metadata": {
        "id": "839a4379"
      },
      "source": [
        "Now letâ€™s have a quick look at how our model is going to behave based on its accuracy and loss changes while training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18e425c",
      "metadata": {
        "id": "d18e425c"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.savefig(\"Task8_Accuracy.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0cfc27",
      "metadata": {
        "id": "6e0cfc27"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc= 'best')\n",
        "plt.savefig(\"Task8_Loss.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "112d0710",
      "metadata": {
        "id": "112d0710"
      },
      "source": [
        "## Testing Next Word Prediction Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7256233f",
      "metadata": {
        "id": "7256233f"
      },
      "source": [
        "Now letâ€™s build a python program to predict the next word using our trained model. For this, we will define some essential functions that will be used in the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e3bc94",
      "metadata": {
        "id": "f0e3bc94"
      },
      "outputs": [],
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfa8f05f",
      "metadata": {
        "id": "cfa8f05f"
      },
      "source": [
        "The sequences must be 40 chars long and the tensor is of the shape (1, 40, 57)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6aeb6cb",
      "metadata": {
        "id": "b6aeb6cb"
      },
      "source": [
        "### The Sample function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c1f31e7",
      "metadata": {
        "id": "5c1f31e7"
      },
      "source": [
        "This function allows us to ask our model what are the next probable characters (The heap simplifies the job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ac4ff7",
      "metadata": {
        "id": "33ac4ff7"
      },
      "outputs": [],
      "source": [
        "def sample(preds, top_n = 3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a8cdaea",
      "metadata": {
        "id": "5a8cdaea"
      },
      "source": [
        "### Prediction function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb2c3987",
      "metadata": {
        "id": "fb2c3987"
      },
      "outputs": [],
      "source": [
        "def predict_completion(text):\n",
        "    original_text = text\n",
        "    generalised = text\n",
        "    completion = ''\n",
        "    while True:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "    text = txt[1:] + next_char\n",
        "    completion += next_char\n",
        "    if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
        "                return completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8432639",
      "metadata": {
        "id": "d8432639"
      },
      "source": [
        "This function is created to predict the next word until space is generated. It will do this by iterating the input, which will ask our RNN model and extract instances from it. Now we will modify the above function to predict multiple characters:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4118ff",
      "metadata": {
        "id": "1f4118ff"
      },
      "source": [
        "### Prediction of multiple completions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8a123c",
      "metadata": {
        "id": "ce8a123c"
      },
      "outputs": [],
      "source": [
        "def predict_completions(text, n = 3):\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e70b0b",
      "metadata": {
        "id": "90e70b0b"
      },
      "source": [
        "Now we will use the sequence of 40 characters that we can use as a base for our predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6524006",
      "metadata": {
        "id": "c6524006"
      },
      "outputs": [],
      "source": [
        "# Sample Test case\n",
        "quotes = [\n",
        "    \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\",\n",
        "    \"That which does not kill us makes us stronger.\",\n",
        "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
        "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
        "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab14010",
      "metadata": {
        "id": "bab14010"
      },
      "source": [
        "Now finally, we can use the model to predict the next word:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ea7189",
      "metadata": {
        "id": "88ea7189"
      },
      "outputs": [],
      "source": [
        "for q in quotes:\n",
        "    seq = q[:SEQUENCE_LENGTH].lower()\n",
        "    print (seq)\n",
        "    print (predict_completions(seq, 5))\n",
        "    print ()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "704e9b1e",
      "metadata": {
        "id": "704e9b1e"
      },
      "source": [
        "The model developed is reliable and efficient enough to be used in realtime scenarios for making predictions using unseen datasets to get the desired results. Hence the project of creating a model for \"Next Word Predictions\" has been successfully completed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee8328e",
      "metadata": {
        "id": "fee8328e"
      },
      "source": [
        "__Note__: The model requires Tensorflow to work with CUDA which is only supported by NVIDIA GPUs. Since the system on which this project was developed had AMD powered GPU, making predictions was not a possibility but the model is reliable enough to be tested elsewhere in systems having all necessary requirements to support the process."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}